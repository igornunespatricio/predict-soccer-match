{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3a5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7270d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/matches.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04fc2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2150 entries, 0 to 2149\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   round             2150 non-null   object        \n",
      " 1   match_date        2144 non-null   datetime64[ns]\n",
      " 2   home_team         2150 non-null   object        \n",
      " 3   guest_team        2150 non-null   object        \n",
      " 4   stadium           2150 non-null   object        \n",
      " 5   date_added        2150 non-null   datetime64[ns]\n",
      " 6   score_home_team   2144 non-null   Int64         \n",
      " 7   score_guest_team  2144 non-null   Int64         \n",
      " 8   winning_team      2144 non-null   string        \n",
      "dtypes: Int64(2), datetime64[ns](2), object(4), string(1)\n",
      "memory usage: 155.5+ KB\n",
      "      round          match_date     home_team  guest_team  \\\n",
      "0  Rodada 1 2023-04-15 16:00:00     Palmeiras      Cuiabá   \n",
      "1  Rodada 1 2023-04-15 16:00:00    América-MG  Fluminense   \n",
      "2  Rodada 1 2023-04-15 18:30:00      Botafogo   São Paulo   \n",
      "3  Rodada 1 2023-04-15 18:30:00    Bragantino       Bahia   \n",
      "4  Rodada 1 2023-04-15 18:30:00  Athletico-PR       Goiás   \n",
      "\n",
      "                    stadium                 date_added  score_home_team  \\\n",
      "0           Arena Palmeiras 2025-07-17 20:16:21.306332                2   \n",
      "1             Independência 2025-07-17 20:16:21.307245                0   \n",
      "2  Nilton Santos (Engenhão) 2025-07-17 20:16:21.314221                2   \n",
      "3           Nabi Abi Chedid 2025-07-17 20:16:21.319415                2   \n",
      "4          Arena da Baixada 2025-07-17 20:16:21.324577                2   \n",
      "\n",
      "   score_guest_team winning_team  \n",
      "0                 1         home  \n",
      "1                 3        guest  \n",
      "2                 1         home  \n",
      "3                 1         home  \n",
      "4                 0         home  \n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d0ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf6b6b",
   "metadata": {},
   "source": [
    "Historical performance: Rolling average of points per game for each team over last N matches (e.g., last 5-10 games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8650ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Create a long-format performance DataFrame upfront\n",
    "def create_performance_df(match_df):\n",
    "    # Home team performances\n",
    "    home = match_df[['match_date', 'home_team', 'score_home_team', 'score_guest_team', 'winning_team']].copy()\n",
    "    home['team'] = home['home_team']\n",
    "    home['opponent'] = home['score_guest_team']\n",
    "    home['is_home'] = True\n",
    "    home['points'] = home['winning_team'].map({'home': 3, 'draw': 1, 'guest': 0})\n",
    "    \n",
    "    # Away team performances\n",
    "    away = match_df[['match_date', 'guest_team', 'score_home_team', 'score_guest_team', 'winning_team']].copy()\n",
    "    away['team'] = away['guest_team']\n",
    "    away['opponent'] = away['score_home_team']\n",
    "    away['is_home'] = False\n",
    "    away['points'] = away['winning_team'].map({'home': 0, 'draw': 1, 'guest': 3})\n",
    "    \n",
    "    # Combine and sort\n",
    "    perf_df = pd.concat([home, away], ignore_index=True)\n",
    "    perf_df = perf_df.sort_values(['team', 'match_date'])\n",
    "    \n",
    "    # Calculate match sequence number for each team\n",
    "    perf_df['team_match_seq'] = perf_df.groupby('team').cumcount() + 1\n",
    "    \n",
    "    return perf_df[['match_date', 'team', 'opponent', 'is_home', 'points', 'team_match_seq']]\n",
    "\n",
    "# 2. Create feature calculation functions\n",
    "def calculate_features(perf_df, window=5):\n",
    "    # Ensure chronological order\n",
    "    perf_df = perf_df.sort_values(['team', 'match_date'])\n",
    "    \n",
    "    # Rolling features\n",
    "    perf_df['rolling_points_avg'] = perf_df.groupby('team')['points'].transform(\n",
    "        lambda x: x.rolling(window, min_periods=1).mean().shift(1))\n",
    "    \n",
    "    perf_df['rolling_points_std'] = perf_df.groupby('team')['points'].transform(\n",
    "        lambda x: x.rolling(window, min_periods=1).std().shift(1))\n",
    "    \n",
    "    # Can add more features here (form, streaks, etc.)\n",
    "    return perf_df\n",
    "\n",
    "# 3. Create match-level features by joining performance data\n",
    "def create_match_features(match_df, perf_df):\n",
    "    # Home team features\n",
    "    match_df = match_df.merge(\n",
    "        perf_df.add_prefix('home_'),\n",
    "        left_on=['match_date', 'home_team'],\n",
    "        right_on=['home_match_date', 'home_team'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Away team features\n",
    "    match_df = match_df.merge(\n",
    "        perf_df.add_prefix('away_'),\n",
    "        left_on=['match_date', 'guest_team'],\n",
    "        right_on=['away_match_date', 'away_team'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return match_df\n",
    "\n",
    "# Main workflow\n",
    "# Assuming df is your original DataFrame\n",
    "perf_df = create_performance_df(df)\n",
    "featured_perf_df = calculate_features(perf_df)\n",
    "final_df = create_match_features(df, featured_perf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ee205",
   "metadata": {},
   "source": [
    "Last 5 games win/draw/loss ratio for both teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92c4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assuming final_df is your dataframe\n",
    "# First sort by match date to ensure chronological order\n",
    "final_df = final_df.sort_values('match_date')\n",
    "\n",
    "# Create dictionaries to store team histories\n",
    "team_history = defaultdict(list)\n",
    "\n",
    "# Function to calculate last 5 matches performance\n",
    "def get_last_5_performance(team, date):\n",
    "    team_matches = team_history[team]\n",
    "    last_5 = [m for m in team_matches if m['date'] < date][-5:]\n",
    "    \n",
    "    if not last_5:\n",
    "        return {'win_ratio': None, 'draw_ratio': None, 'loss_ratio': None}\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    losses = 0\n",
    "    \n",
    "    for match in last_5:\n",
    "        if match['result'] == 'win':\n",
    "            wins += 1\n",
    "        elif match['result'] == 'draw':\n",
    "            draws += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "    \n",
    "    total = wins + draws + losses\n",
    "    return {\n",
    "        'win_ratio': wins / total,\n",
    "        'draw_ratio': draws / total,\n",
    "        'loss_ratio': losses / total\n",
    "    }\n",
    "\n",
    "# First pass to populate team histories\n",
    "for _, row in final_df.iterrows():\n",
    "    if pd.isna(row['match_date']) or pd.isna(row['winning_team']):\n",
    "        continue\n",
    "    \n",
    "    home_team = row['home_team']\n",
    "    guest_team = row['guest_team']\n",
    "    match_date = row['match_date']\n",
    "    \n",
    "    # Determine results for each team\n",
    "    if row['winning_team'] == 'home':\n",
    "        home_result = 'win'\n",
    "        guest_result = 'loss'\n",
    "    elif row['winning_team'] == 'guest':\n",
    "        home_result = 'loss'\n",
    "        guest_result = 'win'\n",
    "    else:  # draw\n",
    "        home_result = 'draw'\n",
    "        guest_result = 'draw'\n",
    "    \n",
    "    # Add to team histories\n",
    "    team_history[home_team].append({\n",
    "        'date': match_date,\n",
    "        'result': home_result,\n",
    "        'opponent': guest_team,\n",
    "        'home_away': 'home'\n",
    "    })\n",
    "    \n",
    "    team_history[guest_team].append({\n",
    "        'date': match_date,\n",
    "        'result': guest_result,\n",
    "        'opponent': home_team,\n",
    "        'home_away': 'away'\n",
    "    })\n",
    "\n",
    "# Second pass to calculate last 5 performance\n",
    "home_win_ratios = []\n",
    "home_draw_ratios = []\n",
    "home_loss_ratios = []\n",
    "guest_win_ratios = []\n",
    "guest_draw_ratios = []\n",
    "guest_loss_ratios = []\n",
    "\n",
    "for _, row in final_df.iterrows():\n",
    "    if pd.isna(row['match_date']):\n",
    "        home_win_ratios.append(None)\n",
    "        home_draw_ratios.append(None)\n",
    "        home_loss_ratios.append(None)\n",
    "        guest_win_ratios.append(None)\n",
    "        guest_draw_ratios.append(None)\n",
    "        guest_loss_ratios.append(None)\n",
    "        continue\n",
    "    \n",
    "    home_perf = get_last_5_performance(row['home_team'], row['match_date'])\n",
    "    guest_perf = get_last_5_performance(row['guest_team'], row['match_date'])\n",
    "    \n",
    "    home_win_ratios.append(home_perf['win_ratio'])\n",
    "    home_draw_ratios.append(home_perf['draw_ratio'])\n",
    "    home_loss_ratios.append(home_perf['loss_ratio'])\n",
    "    \n",
    "    guest_win_ratios.append(guest_perf['win_ratio'])\n",
    "    guest_draw_ratios.append(guest_perf['draw_ratio'])\n",
    "    guest_loss_ratios.append(guest_perf['loss_ratio'])\n",
    "\n",
    "# Add new columns to dataframe\n",
    "final_df['home_win_ratio_last5'] = home_win_ratios\n",
    "final_df['home_draw_ratio_last5'] = home_draw_ratios\n",
    "final_df['home_loss_ratio_last5'] = home_loss_ratios\n",
    "final_df['guest_win_ratio_last5'] = guest_win_ratios\n",
    "final_df['guest_draw_ratio_last5'] = guest_draw_ratios\n",
    "final_df['guest_loss_ratio_last5'] = guest_loss_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7b7cb",
   "metadata": {},
   "source": [
    "Goals scored/conceded in last N matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8ab2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df'\n",
    "# First, sort by match_date to ensure chronological order\n",
    "final_df = final_df.sort_values('match_date').reset_index(drop=True)\n",
    "\n",
    "# Define the number of previous matches to consider\n",
    "N = 5  # You can adjust this based on your needs\n",
    "\n",
    "# Create a long format dataframe with all team performances\n",
    "home_games = final_df[['match_date', 'home_team', 'score_home_team', 'score_guest_team']].copy()\n",
    "home_games['is_home'] = True\n",
    "home_games = home_games.rename(columns={\n",
    "    'home_team': 'team',\n",
    "    'score_home_team': 'goals_scored',\n",
    "    'score_guest_team': 'goals_conceded'\n",
    "})\n",
    "\n",
    "away_games = final_df[['match_date', 'guest_team', 'score_guest_team', 'score_home_team']].copy()\n",
    "away_games['is_home'] = False\n",
    "away_games = away_games.rename(columns={\n",
    "    'guest_team': 'team',\n",
    "    'score_guest_team': 'goals_scored',\n",
    "    'score_home_team': 'goals_conceded'\n",
    "})\n",
    "\n",
    "all_games = pd.concat([home_games, away_games]).sort_values(['team', 'match_date'])\n",
    "\n",
    "# Calculate rolling averages\n",
    "for team in all_games['team'].unique():\n",
    "    team_mask = all_games['team'] == team\n",
    "    all_games.loc[team_mask, 'goals_scored_avg'] = (\n",
    "        all_games.loc[team_mask, 'goals_scored']\n",
    "        .rolling(N, min_periods=1)\n",
    "        .mean()\n",
    "        .shift(1)  # Use previous matches only\n",
    "    )\n",
    "    all_games.loc[team_mask, 'goals_conceded_avg'] = (\n",
    "        all_games.loc[team_mask, 'goals_conceded']\n",
    "        .rolling(N, min_periods=1)\n",
    "        .mean()\n",
    "        .shift(1)\n",
    "    )\n",
    "\n",
    "# Merge back to original dataframe\n",
    "# For home teams\n",
    "final_df = final_df.merge(\n",
    "    all_games[all_games['is_home']][['match_date', 'team', 'goals_scored_avg', 'goals_conceded_avg']],\n",
    "    left_on=['match_date', 'home_team'],\n",
    "    right_on=['match_date', 'team'],\n",
    "    how='left'\n",
    ").rename(columns={\n",
    "    'goals_scored_avg': f'home_team_goals_scored_last_{N}',\n",
    "    'goals_conceded_avg': f'home_team_goals_conceded_last_{N}'\n",
    "}).drop(columns=['team'])\n",
    "\n",
    "# For away teams\n",
    "final_df = final_df.merge(\n",
    "    all_games[~all_games['is_home']][['match_date', 'team', 'goals_scored_avg', 'goals_conceded_avg']],\n",
    "    left_on=['match_date', 'guest_team'],\n",
    "    right_on=['match_date', 'team'],\n",
    "    how='left'\n",
    ").rename(columns={\n",
    "    'goals_scored_avg': f'guest_team_goals_scored_last_{N}',\n",
    "    'goals_conceded_avg': f'guest_team_goals_conceded_last_{N}'\n",
    "}).drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c72b4",
   "metadata": {},
   "source": [
    "Clean sheet frequency (games without conceding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb77e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m home_cs, guest_cs\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Calculate clean sheet frequencies\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m final_df[\u001b[33m'\u001b[39m\u001b[33mhome_team_cs_freq_last5\u001b[39m\u001b[33m'\u001b[39m], final_df[\u001b[33m'\u001b[39m\u001b[33mguest_team_cs_freq_last5\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mcalculate_cs_frequency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcalculate_cs_frequency\u001b[39m\u001b[34m(df, window)\u001b[39m\n\u001b[32m     16\u001b[39m     all_matches.append({\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mteam\u001b[39m\u001b[33m'\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mhome_team\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     18\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mmatch_date\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhome\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m     })\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# For away team perspective\u001b[39;00m\n\u001b[32m     24\u001b[39m     all_matches.append({\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mteam\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mguest_team\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     26\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mmatch_date\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     27\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mgoals_conceded\u001b[39m\u001b[33m'\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mscore_home_team\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33midx\u001b[39m\u001b[33m'\u001b[39m: idx,\n\u001b[32m     29\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mguest\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m     })\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Sort all matches by date\u001b[39;00m\n\u001b[32m     33\u001b[39m all_matches_sorted = \u001b[38;5;28msorted\u001b[39m(all_matches, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\igor\\projects\\predict-soccer-match\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1105\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43mcheck_dict_or_set_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     key = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\igor\\projects\\predict-soccer-match\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2765\u001b[39m, in \u001b[36mcheck_dict_or_set_indexers\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m   2753\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2754\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   2755\u001b[39m \u001b[33;03m    -------\u001b[39;00m\n\u001b[32m   2756\u001b[39m \u001b[33;03m    bool\u001b[39;00m\n\u001b[32m   2757\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   2759\u001b[39m         obj.start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m obj.stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (obj.step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m obj.step != \u001b[32m1\u001b[39m)\n\u001b[32m   2762\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2765\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_dict_or_set_indexers\u001b[39m(key) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2766\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2767\u001b[39m \u001b[33;03m    Check if the indexer is or contains a dict or set, which is no longer allowed.\u001b[39;00m\n\u001b[32m   2768\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2770\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[32m   2771\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m   2772\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[32m   2773\u001b[39m     ):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def calculate_cs_frequency(df, window=5):\n",
    "    \"\"\"\n",
    "    Calculate clean sheet frequency for last N matches regardless of home/away status\n",
    "    Returns two Series: (home_team_cs, guest_team_cs)\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to track team histories\n",
    "    team_history = {}\n",
    "    home_cs = pd.Series(np.nan, index=df.index)\n",
    "    guest_cs = pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # First collect all matches for each team\n",
    "    all_matches = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # For home team perspective\n",
    "        all_matches.append({\n",
    "            'team': row['home_team'],\n",
    "            'date': row['match_date'],\n",
    "            'goals_conceded': row['score_guest_team'],\n",
    "            'idx': idx,\n",
    "            'type': 'home'\n",
    "        })\n",
    "        # For away team perspective\n",
    "        all_matches.append({\n",
    "            'team': row['guest_team'],\n",
    "            'date': row['match_date'],\n",
    "            'goals_conceded': row['score_home_team'],\n",
    "            'idx': idx,\n",
    "            'type': 'guest'\n",
    "        })\n",
    "    \n",
    "    # Sort all matches by date\n",
    "    all_matches_sorted = sorted(all_matches, key=lambda x: x['date'])\n",
    "    \n",
    "    # Process each team separately\n",
    "    for team in df['home_team'].unique():\n",
    "        team_matches = [m for m in all_matches_sorted if m['team'] == team]\n",
    "        \n",
    "        for i, match in enumerate(team_matches):\n",
    "            prev_matches = team_matches[max(0, i-window):i]\n",
    "            \n",
    "            if prev_matches:\n",
    "                clean_sheets = sum(1 for m in prev_matches if m['goals_conceded'] == 0)\n",
    "                freq = clean_sheets / len(prev_matches)\n",
    "            else:\n",
    "                freq = 0\n",
    "            \n",
    "            # Assign to appropriate series\n",
    "            if match['type'] == 'home':\n",
    "                home_cs[match['idx']] = freq\n",
    "            else:\n",
    "                guest_cs[match['idx']] = freq\n",
    "    \n",
    "    return home_cs, guest_cs\n",
    "\n",
    "# Calculate clean sheet frequencies\n",
    "final_df['home_team_cs_freq_last5'], final_df['guest_team_cs_freq_last5'] = calculate_cs_frequency(final_df, window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495d406",
   "metadata": {},
   "source": [
    "Historical H2H record between the two teams (win %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correct_h2h_win_percentage(df, window=5):\n",
    "    \"\"\"\n",
    "    Correctly calculates head-to-head win percentages for both teams\n",
    "    Returns: home_team_h2h_win_pct, guest_team_h2h_win_pct, h2h_draw_pct\n",
    "    \"\"\"\n",
    "    # Initialize results\n",
    "    home_win_pct = pd.Series(0.0, index=df.index)\n",
    "    guest_win_pct = pd.Series(0.0, index=df.index)\n",
    "    draw_pct = pd.Series(0.0, index=df.index)\n",
    "    \n",
    "    # Dictionary to store all matches between team pairs\n",
    "    h2h_history = {}\n",
    "    \n",
    "    # Sort dataframe by match date to process in chronological order\n",
    "    df_sorted = df.sort_values('match_date').reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        home = row['home_team']\n",
    "        guest = row['guest_team']\n",
    "        \n",
    "        # Create consistent team pair key (sorted alphabetically)\n",
    "        team_pair = tuple(sorted((home, guest)))\n",
    "        \n",
    "        if team_pair not in h2h_history:\n",
    "            h2h_history[team_pair] = []\n",
    "        \n",
    "        # Get previous matches between these teams (excluding current match)\n",
    "        prev_matches = h2h_history[team_pair][-window:]\n",
    "        \n",
    "        # Initialize counters\n",
    "        home_wins = 0\n",
    "        guest_wins = 0\n",
    "        draws = 0\n",
    "        \n",
    "        # Analyze previous matches\n",
    "        for match in prev_matches:\n",
    "            if match['winner'] == 'home':\n",
    "                if match['home_team'] == home:\n",
    "                    home_wins += 1\n",
    "                else:\n",
    "                    guest_wins += 1\n",
    "            elif match['winner'] == 'guest':\n",
    "                if match['guest_team'] == home:\n",
    "                    home_wins += 1\n",
    "                else:\n",
    "                    guest_wins += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_matches = len(prev_matches)\n",
    "        if total_matches > 0:\n",
    "            home_win_pct[idx] = home_wins / total_matches\n",
    "            guest_win_pct[idx] = guest_wins / total_matches\n",
    "            draw_pct[idx] = draws / total_matches\n",
    "        \n",
    "        # Store current match in history\n",
    "        h2h_history[team_pair].append({\n",
    "            'home_team': home,\n",
    "            'guest_team': guest,\n",
    "            'winner': row['winning_team']\n",
    "        })\n",
    "    \n",
    "    # Reindex to match original dataframe order\n",
    "    home_win_pct = home_win_pct.reindex(df.index)\n",
    "    guest_win_pct = guest_win_pct.reindex(df.index)\n",
    "    draw_pct = draw_pct.reindex(df.index)\n",
    "    \n",
    "    return home_win_pct, guest_win_pct, draw_pct\n",
    "\n",
    "# Calculate the correct H2H percentages\n",
    "final_df['home_team_h2h_win_pct'], final_df['guest_team_h2h_win_pct'], final_df['h2h_draw_pct'] = \\\n",
    "    calculate_correct_h2h_win_percentage(final_df, window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f2cde",
   "metadata": {},
   "source": [
    "Goal difference trend in H2H matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h2h_goal_diff_trend(df, window=5):\n",
    "    \"\"\"\n",
    "    Calculate goal difference trend in last N H2H matches between teams\n",
    "    Returns two Series: (home_team_h2h_gd_trend, guest_team_h2h_gd_trend)\n",
    "    \"\"\"\n",
    "    # Initialize results\n",
    "    home_gd_trend = pd.Series(0.0, index=df.index)\n",
    "    guest_gd_trend = pd.Series(0.0, index=df.index)\n",
    "    \n",
    "    # Dictionary to store all matches between team pairs\n",
    "    h2h_history = {}\n",
    "    \n",
    "    # Sort dataframe by match date to process in chronological order\n",
    "    df_sorted = df.sort_values('match_date').reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        home = row['home_team']\n",
    "        guest = row['guest_team']\n",
    "        \n",
    "        # Create consistent team pair key (sorted alphabetically)\n",
    "        team_pair = tuple(sorted((home, guest)))\n",
    "        \n",
    "        if team_pair not in h2h_history:\n",
    "            h2h_history[team_pair] = []\n",
    "        \n",
    "        # Get previous matches between these teams (excluding current match)\n",
    "        prev_matches = h2h_history[team_pair][-window:]\n",
    "        \n",
    "        # Initialize goal difference accumulators\n",
    "        home_gd = 0\n",
    "        guest_gd = 0\n",
    "        \n",
    "        # Analyze previous matches\n",
    "        for match in prev_matches:\n",
    "            if match['home_team'] == home:\n",
    "                # Current home team was home in this historical match\n",
    "                home_gd += match['home_score'] - match['guest_score']\n",
    "                guest_gd += match['guest_score'] - match['home_score']\n",
    "            else:\n",
    "                # Current home team was away in this historical match\n",
    "                home_gd += match['guest_score'] - match['home_score']\n",
    "                guest_gd += match['home_score'] - match['guest_score']\n",
    "        \n",
    "        # Calculate average goal difference\n",
    "        if prev_matches:\n",
    "            home_gd_trend[idx] = home_gd / len(prev_matches)\n",
    "            guest_gd_trend[idx] = guest_gd / len(prev_matches)\n",
    "        \n",
    "        # Store current match in history\n",
    "        h2h_history[team_pair].append({\n",
    "            'home_team': home,\n",
    "            'guest_team': guest,\n",
    "            'home_score': row['score_home_team'],\n",
    "            'guest_score': row['score_guest_team']\n",
    "        })\n",
    "    \n",
    "    # Reindex to match original dataframe order\n",
    "    home_gd_trend = home_gd_trend.reindex(df.index)\n",
    "    guest_gd_trend = guest_gd_trend.reindex(df.index)\n",
    "    \n",
    "    return home_gd_trend, guest_gd_trend\n",
    "\n",
    "# Calculate H2H goal difference trends\n",
    "final_df['home_team_h2h_gd_trend'], final_df['guest_team_h2h_gd_trend'] = \\\n",
    "    calculate_h2h_goal_diff_trend(final_df, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2016 entries, 0 to 2015\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   round                             2016 non-null   object        \n",
      " 1   match_date                        2016 non-null   datetime64[ns]\n",
      " 2   home_team                         2016 non-null   object        \n",
      " 3   guest_team                        2016 non-null   object        \n",
      " 4   stadium                           2016 non-null   object        \n",
      " 5   date_added                        2016 non-null   datetime64[ns]\n",
      " 6   score_home_team                   2016 non-null   Int64         \n",
      " 7   score_guest_team                  2016 non-null   Int64         \n",
      " 8   winning_team                      2016 non-null   object        \n",
      " 9   home_match_date                   2016 non-null   datetime64[ns]\n",
      " 10  home_opponent                     2016 non-null   Int64         \n",
      " 11  home_is_home                      2016 non-null   bool          \n",
      " 12  home_points                       2016 non-null   int64         \n",
      " 13  home_team_match_seq               2016 non-null   int64         \n",
      " 14  home_rolling_points_avg           2001 non-null   float64       \n",
      " 15  home_rolling_points_std           1986 non-null   float64       \n",
      " 16  away_match_date                   2016 non-null   datetime64[ns]\n",
      " 17  away_team                         2016 non-null   object        \n",
      " 18  away_opponent                     2016 non-null   Int64         \n",
      " 19  away_is_home                      2016 non-null   bool          \n",
      " 20  away_points                       2016 non-null   int64         \n",
      " 21  away_team_match_seq               2016 non-null   int64         \n",
      " 22  away_rolling_points_avg           2002 non-null   float64       \n",
      " 23  away_rolling_points_std           1988 non-null   float64       \n",
      " 24  home_win_ratio_last5              2001 non-null   float64       \n",
      " 25  home_draw_ratio_last5             2001 non-null   float64       \n",
      " 26  home_loss_ratio_last5             2001 non-null   float64       \n",
      " 27  guest_win_ratio_last5             2002 non-null   float64       \n",
      " 28  guest_draw_ratio_last5            2002 non-null   float64       \n",
      " 29  guest_loss_ratio_last5            2002 non-null   float64       \n",
      " 30  home_team_goals_scored_last_5     2001 non-null   float64       \n",
      " 31  home_team_goals_conceded_last_5   2001 non-null   float64       \n",
      " 32  guest_team_goals_scored_last_5    2002 non-null   float64       \n",
      " 33  guest_team_goals_conceded_last_5  2002 non-null   float64       \n",
      " 34  home_team_cs_freq_last5           2016 non-null   float64       \n",
      " 35  guest_team_cs_freq_last5          2016 non-null   float64       \n",
      " 36  home_team_h2h_win_pct             2016 non-null   float64       \n",
      " 37  guest_team_h2h_win_pct            2016 non-null   float64       \n",
      " 38  h2h_draw_pct                      2016 non-null   float64       \n",
      " 39  home_team_h2h_gd_trend            2016 non-null   float64       \n",
      " 40  guest_team_h2h_gd_trend           2016 non-null   float64       \n",
      "dtypes: Int64(4), bool(2), datetime64[ns](4), float64(21), int64(4), object(6)\n",
      "memory usage: 626.2+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1060d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['home_adv_pts_diff'] = final_df['home_rolling_points_avg'] - final_df['away_rolling_points_avg']\n",
    "final_df['home_goal_dominance_last5'] = final_df['home_team_goals_scored_last_5'] - final_df['home_team_goals_conceded_last_5']\n",
    "final_df['away_goal_dominance_last5'] = final_df['guest_team_goals_scored_last_5'] - final_df['guest_team_goals_conceded_last_5']\n",
    "final_df['home_win_power'] = final_df['home_win_ratio_last5'] * final_df['home_rolling_points_avg']\n",
    "final_df['away_win_power'] = final_df['guest_win_ratio_last5'] * final_df['away_rolling_points_avg']\n",
    "final_df['is_stalemate'] = (final_df['home_rolling_points_avg'] - final_df['away_rolling_points_avg']).abs() < 0.5\n",
    "# Avoid division by zero by adding a small epsilon (e.g., 0.1)\n",
    "epsilon = 0.1\n",
    "\n",
    "final_df['home_defense_strength'] = (\n",
    "    final_df['home_team_cs_freq_last5'] / \n",
    "    (final_df['home_team_goals_conceded_last_5'] + epsilon)\n",
    ")\n",
    "\n",
    "final_df['away_defense_strength'] = (\n",
    "    final_df['guest_team_cs_freq_last5'] / \n",
    "    (final_df['guest_team_goals_conceded_last_5'] + epsilon)\n",
    ")\n",
    "\n",
    "final_df['home_away_strength_diff'] = final_df['home_rolling_points_avg'] - final_df['away_rolling_points_avg']\n",
    "\n",
    "final_df['home_attack_defense_ratio'] = final_df['home_team_goals_scored_last_5'] / (final_df['home_team_goals_conceded_last_5'] + 0.1)\n",
    "final_df['away_attack_defense_ratio'] = final_df['guest_team_goals_scored_last_5'] / (final_df['guest_team_goals_conceded_last_5'] + 0.1)\n",
    "\n",
    "final_df['home_win_streak'] = final_df['home_win_ratio_last5'] * final_df['home_team_match_seq']\n",
    "final_df['away_loss_streak'] = final_df['guest_loss_ratio_last5'] * final_df['away_team_match_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ca905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  89  24]\n",
      " [  2  77  11]\n",
      " [  4 145  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        draw      0.143     0.009     0.017       114\n",
      "       guest      0.248     0.856     0.384        90\n",
      "        home      0.568     0.236     0.333       195\n",
      "\n",
      "    accuracy                          0.311       399\n",
      "   macro avg      0.319     0.367     0.245       399\n",
      "weighted avg      0.374     0.311     0.254       399\n",
      "\n",
      "                             Feature  Importance\n",
      "6             guest_draw_ratio_last5    6.108260\n",
      "3              home_draw_ratio_last5    6.050317\n",
      "31                  away_loss_streak    6.016248\n",
      "12           home_team_cs_freq_last5    5.201857\n",
      "30                   home_win_streak    4.842217\n",
      "15            guest_team_h2h_win_pct    4.423915\n",
      "10    guest_team_goals_scored_last_5    4.339331\n",
      "8      home_team_goals_scored_last_5    3.782670\n",
      "16                      h2h_draw_pct    3.657375\n",
      "14             home_team_h2h_win_pct    3.385343\n",
      "28         home_attack_defense_ratio    3.315071\n",
      "9    home_team_goals_conceded_last_5    3.187656\n",
      "4              home_loss_ratio_last5    3.167432\n",
      "11  guest_team_goals_conceded_last_5    3.105368\n",
      "24                      is_stalemate    3.028851\n",
      "18           guest_team_h2h_gd_trend    2.987330\n",
      "13          guest_team_cs_freq_last5    2.925926\n",
      "17            home_team_h2h_gd_trend    2.851516\n",
      "25             home_defense_strength    2.747211\n",
      "26             away_defense_strength    2.720048\n",
      "20         home_goal_dominance_last5    2.698449\n",
      "5              guest_win_ratio_last5    2.443754\n",
      "22                    home_win_power    2.284562\n",
      "29         away_attack_defense_ratio    2.109288\n",
      "21         away_goal_dominance_last5    1.944561\n",
      "23                    away_win_power    1.705591\n",
      "2               home_win_ratio_last5    1.658136\n",
      "0            home_rolling_points_avg    1.624675\n",
      "19                 home_adv_pts_diff    1.580022\n",
      "7             guest_loss_ratio_last5    1.548194\n",
      "27           home_away_strength_diff    1.355522\n",
      "1            away_rolling_points_avg    1.203308\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load data (assuming `final_df` from previous steps)\n",
    "df = final_df.copy()\n",
    "\n",
    "# Encode target variable (winning_team: home/draw/guest)\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['winning_team'])  # 0=home, 1=draw, 2=guest\n",
    "\n",
    "# Select features (modify as needed)\n",
    "features = [\n",
    "    'home_rolling_points_avg', 'away_rolling_points_avg',\n",
    "\n",
    "    'home_win_ratio_last5', 'home_draw_ratio_last5', 'home_loss_ratio_last5', 'guest_win_ratio_last5', 'guest_draw_ratio_last5', 'guest_loss_ratio_last5',\n",
    "\n",
    "    'home_team_goals_scored_last_5', 'home_team_goals_conceded_last_5', 'guest_team_goals_scored_last_5', 'guest_team_goals_conceded_last_5',\n",
    "\n",
    "    'home_team_cs_freq_last5', 'guest_team_cs_freq_last5',\n",
    "\n",
    "    'home_team_h2h_win_pct', 'guest_team_h2h_win_pct', 'h2h_draw_pct',\n",
    "\n",
    "    'home_team_h2h_gd_trend', 'guest_team_h2h_gd_trend',\n",
    "\n",
    "    'home_adv_pts_diff', 'home_goal_dominance_last5', 'away_goal_dominance_last5',\n",
    "\n",
    "    'home_win_power', 'away_win_power', 'is_stalemate', 'home_defense_strength', 'away_defense_strength',\n",
    "\n",
    "    'home_away_strength_diff', 'home_attack_defense_ratio', 'away_attack_defense_ratio', 'home_win_streak', 'away_loss_streak'\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    n_estimators=300,  # Increased\n",
    "    max_depth=5,       # Deeper trees\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,     # Prevent overfitting\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,     # L1 regularization\n",
    "    reg_lambda=0.1,    # L2 regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,              # More trees\n",
    "    depth=6,                     # Slightly deeper\n",
    "    learning_rate=0.02,           # Slower learning\n",
    "    l2_leaf_reg=5,               # Stronger regularization\n",
    "    class_weights=[1, 3, 1],     # Focus on draws\n",
    "    eval_metric='TotalF1',       # Optimize for F1-score\n",
    "    early_stopping_rounds=50,    # Prevent overfitting\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Pass sample_weight during training\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Decode labels back to original values\n",
    "class_names = le.inverse_transform([0, 1, 2])  # ['home', 'draw', 'guest']\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=class_names,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# Get feature importances\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314796f7",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319df80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 0.6919 | Test Acc: 0.2531\n",
      "Epoch 2/100 | Loss: 1.4095 | Test Acc: 0.3759\n",
      "Epoch 3/100 | Loss: 1.3032 | Test Acc: 0.4436\n",
      "Epoch 4/100 | Loss: 1.1454 | Test Acc: 0.4712\n",
      "Epoch 5/100 | Loss: 0.5684 | Test Acc: 0.4887\n",
      "Epoch 6/100 | Loss: 0.5620 | Test Acc: 0.4912\n",
      "Epoch 7/100 | Loss: 1.0399 | Test Acc: 0.4912\n",
      "Epoch 8/100 | Loss: 0.5779 | Test Acc: 0.4862\n",
      "Epoch 9/100 | Loss: 0.5354 | Test Acc: 0.4887\n",
      "Epoch 10/100 | Loss: 0.5540 | Test Acc: 0.4887\n",
      "Epoch 11/100 | Loss: 1.2557 | Test Acc: 0.4887\n",
      "Epoch 12/100 | Loss: 1.1698 | Test Acc: 0.4887\n",
      "Epoch 13/100 | Loss: 1.0950 | Test Acc: 0.4937\n",
      "Epoch 14/100 | Loss: 0.6117 | Test Acc: 0.4862\n",
      "Epoch 15/100 | Loss: 1.2947 | Test Acc: 0.4887\n",
      "Epoch 16/100 | Loss: 0.5155 | Test Acc: 0.4937\n",
      "Epoch 17/100 | Loss: 0.4174 | Test Acc: 0.4862\n",
      "Epoch 18/100 | Loss: 0.4722 | Test Acc: 0.4937\n",
      "Epoch 19/100 | Loss: 1.2593 | Test Acc: 0.4987\n",
      "Epoch 20/100 | Loss: 0.8057 | Test Acc: 0.4987\n",
      "Epoch 21/100 | Loss: 0.4959 | Test Acc: 0.4887\n",
      "Epoch 22/100 | Loss: 1.1399 | Test Acc: 0.4912\n",
      "Epoch 23/100 | Loss: 1.6041 | Test Acc: 0.4937\n",
      "Epoch 24/100 | Loss: 0.8862 | Test Acc: 0.4887\n",
      "Epoch 25/100 | Loss: 0.9010 | Test Acc: 0.4937\n",
      "Epoch 26/100 | Loss: 0.8255 | Test Acc: 0.4937\n",
      "Epoch 27/100 | Loss: 0.6110 | Test Acc: 0.4887\n",
      "Epoch 28/100 | Loss: 0.6972 | Test Acc: 0.4987\n",
      "Epoch 29/100 | Loss: 0.5000 | Test Acc: 0.4962\n",
      "Epoch 30/100 | Loss: 0.8396 | Test Acc: 0.4962\n",
      "Epoch 31/100 | Loss: 1.4377 | Test Acc: 0.5063\n",
      "Epoch 32/100 | Loss: 1.2664 | Test Acc: 0.4987\n",
      "Epoch 33/100 | Loss: 1.2168 | Test Acc: 0.4912\n",
      "Epoch 34/100 | Loss: 1.1427 | Test Acc: 0.5038\n",
      "Epoch 35/100 | Loss: 0.5181 | Test Acc: 0.4962\n",
      "Epoch 36/100 | Loss: 1.0087 | Test Acc: 0.5013\n",
      "Epoch 37/100 | Loss: 0.7777 | Test Acc: 0.4987\n",
      "Epoch 38/100 | Loss: 0.7920 | Test Acc: 0.4987\n",
      "Epoch 39/100 | Loss: 0.9318 | Test Acc: 0.4862\n",
      "Epoch 40/100 | Loss: 1.5186 | Test Acc: 0.5013\n",
      "Epoch 41/100 | Loss: 0.7395 | Test Acc: 0.4912\n",
      "Epoch 42/100 | Loss: 0.6089 | Test Acc: 0.4962\n",
      "Epoch 43/100 | Loss: 1.0941 | Test Acc: 0.4987\n",
      "Epoch 44/100 | Loss: 0.8415 | Test Acc: 0.4962\n",
      "Epoch 45/100 | Loss: 2.0149 | Test Acc: 0.5013\n",
      "Epoch 46/100 | Loss: 0.6966 | Test Acc: 0.4962\n",
      "Epoch 47/100 | Loss: 0.9094 | Test Acc: 0.4887\n",
      "Epoch 48/100 | Loss: 0.8610 | Test Acc: 0.4887\n",
      "Epoch 49/100 | Loss: 0.5722 | Test Acc: 0.4912\n",
      "Epoch 50/100 | Loss: 1.4632 | Test Acc: 0.4862\n",
      "Epoch 51/100 | Loss: 0.9276 | Test Acc: 0.4887\n",
      "Epoch 52/100 | Loss: 0.8012 | Test Acc: 0.4887\n",
      "Epoch 53/100 | Loss: 2.7036 | Test Acc: 0.4962\n",
      "Epoch 54/100 | Loss: 0.4452 | Test Acc: 0.5013\n",
      "Epoch 55/100 | Loss: 0.9321 | Test Acc: 0.4962\n",
      "Epoch 56/100 | Loss: 1.5491 | Test Acc: 0.4937\n",
      "Epoch 57/100 | Loss: 0.6049 | Test Acc: 0.4987\n",
      "Epoch 58/100 | Loss: 1.2965 | Test Acc: 0.4987\n",
      "Epoch 59/100 | Loss: 0.5181 | Test Acc: 0.4912\n",
      "Epoch 60/100 | Loss: 0.5430 | Test Acc: 0.4962\n",
      "Epoch 61/100 | Loss: 0.7524 | Test Acc: 0.4937\n",
      "Epoch 62/100 | Loss: 0.6377 | Test Acc: 0.4887\n",
      "Epoch 63/100 | Loss: 0.5252 | Test Acc: 0.4862\n",
      "Epoch 64/100 | Loss: 0.8331 | Test Acc: 0.4862\n",
      "Epoch 65/100 | Loss: 0.6943 | Test Acc: 0.4862\n",
      "Epoch 66/100 | Loss: 0.5563 | Test Acc: 0.4862\n",
      "Epoch 67/100 | Loss: 0.7655 | Test Acc: 0.4987\n",
      "Epoch 68/100 | Loss: 0.8575 | Test Acc: 0.4962\n",
      "Epoch 69/100 | Loss: 1.6965 | Test Acc: 0.5013\n",
      "Epoch 70/100 | Loss: 0.5620 | Test Acc: 0.4937\n",
      "Epoch 71/100 | Loss: 0.8226 | Test Acc: 0.4912\n",
      "Epoch 72/100 | Loss: 0.6583 | Test Acc: 0.4987\n",
      "Epoch 73/100 | Loss: 1.8028 | Test Acc: 0.4962\n",
      "Epoch 74/100 | Loss: 0.5802 | Test Acc: 0.4962\n",
      "Epoch 75/100 | Loss: 0.8982 | Test Acc: 0.4912\n",
      "Epoch 76/100 | Loss: 0.7380 | Test Acc: 0.4987\n",
      "Epoch 77/100 | Loss: 0.7114 | Test Acc: 0.4962\n",
      "Epoch 78/100 | Loss: 0.5177 | Test Acc: 0.4987\n",
      "Epoch 79/100 | Loss: 0.9991 | Test Acc: 0.4962\n",
      "Epoch 80/100 | Loss: 1.1518 | Test Acc: 0.4937\n",
      "Epoch 81/100 | Loss: 1.0826 | Test Acc: 0.4962\n",
      "Epoch 82/100 | Loss: 1.0708 | Test Acc: 0.4962\n",
      "Epoch 83/100 | Loss: 0.9201 | Test Acc: 0.4887\n",
      "Epoch 84/100 | Loss: 0.8724 | Test Acc: 0.4937\n",
      "Epoch 85/100 | Loss: 0.5341 | Test Acc: 0.4912\n",
      "Epoch 86/100 | Loss: 0.6013 | Test Acc: 0.4837\n",
      "Epoch 87/100 | Loss: 0.4985 | Test Acc: 0.4887\n",
      "Epoch 88/100 | Loss: 0.5723 | Test Acc: 0.4937\n",
      "Epoch 89/100 | Loss: 0.9852 | Test Acc: 0.4937\n",
      "Epoch 90/100 | Loss: 0.5212 | Test Acc: 0.4937\n",
      "Epoch 91/100 | Loss: 0.5607 | Test Acc: 0.4987\n",
      "Epoch 92/100 | Loss: 1.0639 | Test Acc: 0.4912\n",
      "Epoch 93/100 | Loss: 1.5342 | Test Acc: 0.4987\n",
      "Epoch 94/100 | Loss: 0.5851 | Test Acc: 0.4987\n",
      "Epoch 95/100 | Loss: 1.2019 | Test Acc: 0.5013\n",
      "Epoch 96/100 | Loss: 0.4879 | Test Acc: 0.4887\n",
      "Epoch 97/100 | Loss: 0.7024 | Test Acc: 0.4862\n",
      "Epoch 98/100 | Loss: 0.4676 | Test Acc: 0.4912\n",
      "Epoch 99/100 | Loss: 0.7733 | Test Acc: 0.4912\n",
      "Epoch 100/100 | Loss: 1.1634 | Test Acc: 0.4937\n",
      "Confusion Matrix:\n",
      "[[ 15   0  99]\n",
      " [ 10   0  80]\n",
      " [ 13   0 182]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        home       0.39      0.13      0.20       114\n",
      "        draw       0.00      0.00      0.00        90\n",
      "        away       0.50      0.93      0.65       195\n",
      "\n",
      "    accuracy                           0.49       399\n",
      "   macro avg       0.30      0.35      0.28       399\n",
      "weighted avg       0.36      0.49      0.38       399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\igor\\projects\\predict-soccer-match\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\igor\\projects\\predict-soccer-match\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\igor\\projects\\predict-soccer-match\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: SMOTE to boost minority classes (if any)\n",
    "# Step 2: RandomUnderSampler to reduce majority class (draws)\n",
    "pipeline = Pipeline([\n",
    "    ('oversample', SMOTE(sampling_strategy='minority')),  # Boost home/away wins\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy={1: 150}))  # Reduce draws\n",
    "])\n",
    "\n",
    "X_res, y_res = pipeline.fit_resample(X_train, y_train)\n",
    "X_res, y_res = torch.FloatTensor(X_res), torch.LongTensor(y_res)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_data = TensorDataset(X_res, y_res)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "class SoccerPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(32, 3)  # 3 output classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.fc3(x)  # No softmax (handled in loss)\n",
    "        return x\n",
    "\n",
    "model = SoccerPredictor(input_size=len(features))\n",
    "\n",
    "# Class weights (penalize misclassifying draws)\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = torch.FloatTensor(class_weights / class_weights.sum())\n",
    "# Adjust class weights (penalize missing draws more)\n",
    "class_weights = torch.FloatTensor([1, 3, 1])  # [home, draw, away]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss with class weights (weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        _, preds = torch.max(test_outputs, 1)\n",
    "        accuracy = (preds == y_test).float().mean()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f} | Test Acc: {accuracy:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).argmax(dim=1)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['home', 'draw', 'away']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
